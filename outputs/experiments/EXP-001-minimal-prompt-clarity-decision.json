{
  "experiment_id": "EXP-001-minimal-prompt-clarity",
  "experiment_title": "First Controlled Intelligence Experiment - Infrastructure Validation",
  "phase": "5.3.3",
  "status": "INITIALIZED",
  "created_at": "2026-02-07T00:00:00Z",
  "decided_at": null,
  "execution_status": "READY_FOR_EXECUTION",
  "protocol_compliance": {
    "phase_5_3_1_validated": false,
    "single_variable_enforced": true,
    "phase_5_2_metrics_only": true,
    "baseline_immutable": true,
    "reproducibility_enabled": true,
    "human_in_loop": true
  },
  "specification": {
    "hypothesis": "A minor clarity-oriented prompt adjustment will reduce correction pressure without affecting latency, hallucination risk, or task completion.",
    "changed_variable": "prompt_clarity_sentence (single sentence appended to prompt)",
    "baseline_id": "v1",
    "variant_id": "prompt-clarity-v2",
    "minimum_runs": 5,
    "dataset": "EXP-001-fixed-dataset.json (30 conversations, frozen)"
  },
  "metrics": {
    "primary_metrics": [
      "correction_rate",
      "retry_rate",
      "turns_to_completion"
    ],
    "guardrail_metrics": [
      "hallucination_proxy_rate",
      "self_correction_frequency",
      "latency_per_completed_task",
      "task_completion_rate"
    ],
    "memory_metrics": [
      "memory_reference_rate",
      "memory_improvement_rate"
    ]
  },
  "automatic_rejection_criteria": [
    "hallucination_proxy_rate increases beyond baseline variance",
    "latency_per_completed_task increases without quality improvement",
    "task_completion_rate drops",
    "invariant alarms appear",
    "control_flow divergence detected"
  ],
  "execution_results": {
    "baseline_execution_completed": false,
    "variant_execution_completed": false,
    "metrics_computed": false,
    "comparison_generated": false,
    "reproducibility_recorded": false
  },
  "metrics_comparison": {
    "baseline_metrics": null,
    "variant_metrics": null,
    "improvements": [],
    "regressions": [],
    "inconclusive": []
  },
  "decision": {
    "outcome": null,
    "justification": null,
    "evidence": null,
    "reviewer": null,
    "approved": false
  },
  "artifacts": {
    "report_md": null,
    "comparison_json": null,
    "baseline_reproducibility": null,
    "variant_reproducibility": null,
    "decision_record": null
  },
  "infrastructure_validation": {
    "spec_validation_passed": false,
    "harness_execution_successful": false,
    "all_artifacts_created": false,
    "reproducibility_verified": false,
    "no_agent_modification": true,
    "baseline_preservation": true
  },
  "notes": "This experiment validates the experimentation platform, not the prompt optimization. A clean rejection is a successful infrastructure outcome. All decisions must be evidence-based with no subjective override."
}
